{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperación de recursos de la web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se van a mostrar varias formas de recuperar recursos que se encuentran en la web:\n",
    "\n",
    "* Recuperación via http\n",
    "\n",
    "* Recuperación con el módulo urllib.\n",
    "\n",
    "* Recuperación con el módulo Request\n",
    "\n",
    "__Recuperación via http__\n",
    "\n",
    "Un socket proporciona una conexión de doble sentido entre dos programas, de manera que es posible tanto leer como escribir en el mismo socket. Si se escribe algo en un socket, es enviado hacia la aplicación que está al otro lado del socket. Si se lee desde un socket, se obtienen los datos que la otra aplicación ha enviado.\n",
    "\n",
    "En Python existe un soporte integrado para los sockets.\n",
    "\n",
    "El protocolo para el intercambio de recursos web es HTTP. En este  protocolo para pedir un documento a un servidor web se escribe una línea en la cual el segundo parámetro es la página web que estamos solicitando, y a continuación enviamos una línea en blanco:\n",
    "\n",
    "            GET servidor web HTTP/1.0\n",
    "\n",
    "El servidor web responderá con una cabecera que contiene cierta información acerca del documento y una línea en blanco, seguido por el contenido del documento.\n",
    "\n",
    "En el siguiente ejemplo se va a recuperar una imagen. Para ello se realiza una conexión con el puerto 80 del servidor y se envía el comando GET seguido por una línea en blanco. Una vez enviada la línea en blanco, se utiliza un bucle que recibe los datos desde el socket en bloques de 512 caracteres y se  imprime en pantalla hasta que no quedan más datos por leer (recv() devuelve una cadena vacía)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "misock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "misock.connect(('4.bp.blogspot.com', 80))\n",
    "cmd = 'GET http://4.bp.blogspot.com/-aqPvTTwBDJQ/W4FInd5fTtI/AAAAAAAACkY/6536BHcuVlEh4YTRqIVi6DUFGb1FZWEWQCK4BGAYYCw/s1600/DSC_0166-1.jpg HTTP/1.1\\r\\n\\r\\n'.encode()\n",
    "misock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    datos = misock.recv(512)\n",
    "    if (len(datos) < 1):\n",
    "        break\n",
    "    print(datos)\n",
    "misock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida comienza con las cabecera que el servidor web envía para describir el documento. Por ejemplo Content-Type indica que es imagen en formato jpeg (image/jpeg). A continuación de la cabecera, añade una línea en blanco para indicar el final de la misma, y envía los datos reales del fichero.\n",
    "\n",
    "\n",
    "Se puede mejorar el programa guardando los datos en una cadena, recortando las cabeceras y luego guardando los datos de la imagen en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import time\n",
    "\n",
    "misock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "misock.connect(('4.bp.blogspot.com', 80))\n",
    "cmd = 'GET http://4.bp.blogspot.com/-aqPvTTwBDJQ/W4FInd5fTtI/AAAAAAAACkY/6536BHcuVlEh4YTRqIVi6DUFGb1FZWEWQCK4BGAYYCw/s1600/DSC_0166-1.jpg HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "misock.send(cmd)\n",
    "contador=0\n",
    "imagen=\"\".encode()\n",
    "while True:\n",
    "    datos = misock.recv(5120)\n",
    "    if (len(datos) < 1):\n",
    "        break\n",
    "    imagen=imagen+datos\n",
    "misock.close()\n",
    "\n",
    "#Búsqueda del final de la cabecera\n",
    "pos=imagen.find(\"\\r\\n\\r\\n\".encode())\n",
    "print (imagen[:pos])\n",
    "\n",
    "#Saltar la cabecera y guardar los datos de la imagen\n",
    "imagen=imagen[pos+4:]\n",
    "manf=open(\"tren.jpg\",\"wb\")\n",
    "manf.write(imagen)\n",
    "manf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que el programa termina, se pueden ver los datos de la imagen abriendo el archivo tren.jpg con un editor de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='tren.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recuperación con el módulo urllib__\n",
    "\n",
    "urllib es una librería que permite tratar una página web de forma parecida a la apertura de un fichero, de forma que la librería gestiona de manera transparente todo lo referente al protocolo HTTP y los detalles de la cabecera.\n",
    "\n",
    "Una vez que la página web ha sido abierta con urllib.request.urlopen, se puede tratar como un archivo y leer a través de ella usando un bucle for.\n",
    "\n",
    "Cuando se recupera la página web, sólo se accede al contenido puesto las cabeceras aunque se envián,  el código de urllib se queda con ellas y sólo devuelve los datos.\n",
    "\n",
    "En el siguiente ejemplo se recupera la información de una página web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "manf = urllib.request.urlopen('http://informatica.ucm.es')\n",
    "for line in manf:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En el siguiente programa se procesa la información de un página web y se calcula la frecuencia de cada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "contadores=dict()\n",
    "manf = urllib.request.urlopen('http://informatica.ucm.es')\n",
    "for linea in manf:\n",
    "    palabras=linea.split()\n",
    "    for palabra in palabras:\n",
    "        contadores[palabra]=contadores.get(palabra,0)+1\n",
    "print (contadores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería urllib también se puede utilizar para recuperar ficheros que no son de texto  como un archivo de imagen o de video, y para los que se requiere hacer una copia de la URL en un archivo local.\n",
    "\n",
    "En estos casos se usa el método read para descargar el contenido completo del documento en una variable de tipo cadena y luego escribir la información a un archivo local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "img = urllib.request.urlopen('https://www.vialibre-ffe.com/multimedia/galerias/trenesdeantes/03.jpg').read()\n",
    "manf=open(\"portada.jpg\",\"wb\")\n",
    "manf.write(img)\n",
    "manf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El programa lee todos los datos de una sola vez a través de la red y los almacena en la variable img en la memoria principal  y luego abre el fichero portada.jpg y escribe los datos en el disco. Esto funciona sólo si el tamaño del fichero es menor que el tamaño de la memoria del PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='portada.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero si se trata de un fichero demasiado grande el programa puede fallar cuando el equipo se quede sin memoria. Para evitar agotar la memoria, se puede recuperar los datos en bloques, y luego escribir cada bloque en el disco antes de recuperar el siguiente. De este modo el programa puede leer archivos de cualquier tamaño sin usar toda la memoria del equipo.\n",
    "\n",
    "En este ejemplo, se leen 100.000 caracteres cada vez y luego se escriben esos caracteres en el archivo portada.jpg, antes de recuperar los 100.000 caracteres siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "img = urllib.request.urlopen('https://www.vialibre-ffe.com/multimedia/galerias/trenesdeantes/03.jpg')\n",
    "manf=open(\"portada.jpg\",\"wb\")\n",
    "tamano=0\n",
    "while True:\n",
    "    info=img.read(100000)\n",
    "    if len(info)<1:\n",
    "        break\n",
    "    tamano=tamano+len(info)\n",
    "    manf.write(info)\n",
    "print(tamano,\" caracteres copiados\")\n",
    "manf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una versión más sofisticada sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "print (\"Entrar una url\")\n",
    "urlstr=input().strip()\n",
    "img = urllib.request.urlopen(urlstr)\n",
    "words=urlstr.split('/')\n",
    "fname=words[-1]\n",
    "\n",
    "if os.path.exists(fname):\n",
    "    if input(\"¿Reemplazar archivo \"+\" S/n?\")!=\"S\":\n",
    "        print (\"Datos no copiados\")\n",
    "        exit()\n",
    "    print (\"Reemplazando datos\",fname)\n",
    "\n",
    "\n",
    "manf=open(fname,\"wb\")\n",
    "tamano=0\n",
    "while True:\n",
    "    info=img.read(100000)\n",
    "    if len(info)<1:\n",
    "        break\n",
    "    tamano=tamano+len(info)\n",
    "    manf.write(info)\n",
    "print(tamano,\" caracteres copiados \", fname)\n",
    "manf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recuperación con el módulo request__\n",
    "\n",
    "El módulo requests permite bajarse archivos de la red de una forma transparente. No se encuentra instalado por defecto con Python.\n",
    "\n",
    "La función get() del módulo requests toma una cadena que representa la url que se quiere descargar. El resultado de la llamada es un objeto de tipo Response que contiene la respuesta que el servidor web devuelve como respuesta a la petición."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import request\n",
    "res=requests.get(\"http://informatica.ucm.es\")\n",
    "if res.status.code==request.codes.ok:\n",
    "    print(\"len(res.text)\")\n",
    "    print(res.text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo además de recuperar la pagina descrita, se ha comprobado que la descarga se ha realizado con éxito chequeando el valor del atributo status_code del objeto Response. Si el valor que toma es requests.codes.ok significa que se ha realizado correctamente, y la descargada se ha almacenado como una cadena en la variable text del objeto Response.\n",
    "\n",
    "Otra forma de comprobar si una descarga se ha realizado con éxito consiste en utilizar el método raise_for_status() del objeto Response. Este método lanzará una excepción si se ha producido algún error en la descarga y no hará nada en caso de que la descarga se haya realizado con éxito. Es por ello que una buena práctica consiste en encerrar la llamada al método raise_for_status() entre un try/except con el objetivo de tratar los casos en que se produzca una descarga errónea."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import request\n",
    "res=requests.get(\"http://informatica.ucm.es\")\n",
    "try:\n",
    "    res.raise_for_status()\n",
    "except:\n",
    "    print (\"Hubo un problema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar que es la llamada al método __raise_for_status()__ hay que realizarlo siempre después de llamar al método __requests.get()__ dado que el objetivo es asegurarse que la descarga se realizó con éxito antes de que el programa continúe su ejecución.\n",
    "\n",
    "Una vez que ha realizado la descarga, lo que interesa es guardar el contenido en un archivo. Para ello se puede utilizar la función __open()__ y el método __write()__. En este sentido lo primero que hay que hacer es abrir un fichero en modo __“wb”__(escribir un modo binario), y a continuación escribir al fichero usando un bucle for que utilice el método __iter_content__ del objeto __Response__."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import request\n",
    "res=requests.get(\"http://informatica.ucm.es\")\n",
    "try:\n",
    "    res.raise_for_status()\n",
    "    archivo=open(\"Archivo.txt\",\"wb\")\n",
    "    for bloque in res.iter_content(10000):\n",
    "       archivo.write(bloque)\n",
    "    archivo.close()\n",
    "except:\n",
    "    print (\"Hubo un problema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar que el método iter_content recupera bloques de contenido en cada iteración a través del bucle. Cada bloque es un conjunto de bytes de datos en un tamaño igual al especificado. Así  mismo observar que el método __write()__ retorna el número de bytes escritos al fichero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El “web scraping” consiste en escribir un programa que finge ser un navegador web y recupera páginas, examinando luego los datos de esas páginas para encontrar ciertos patrones.\n",
    "\n",
    "Por ejemplo los buscadores:\n",
    "\n",
    "* Buscan en el código de una página web, extraen los enlaces a otras páginas y recuperan esas páginas, extrayendo los enlaces que haya en ellas y así sucesivamente. \n",
    "\n",
    "* Usan la frecuencia con que las páginas que encuentra enlazan hacia una página concreta para calcular la “importancia” de esa página, y la posición en la que debe aparecer dentro de sus resultados de búsqueda.\n",
    "\n",
    "Se van a estudiar dos formas de analizar páginas web:\n",
    "\n",
    "* Mediante expresiones regulares.\n",
    "\n",
    "* Mediante la librería BeautifulSoup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Expresiones regulares__\n",
    "\n",
    "Un forma fácil de analizar HTML consiste en utilizar expresiones regulares para hacer búsquedas repetidas que extraigan subcadenas coincidentes con un modelo concreto.\n",
    "\n",
    "Considerar por ejemplo una página web que contiene enlaces y se quieren detectar dicho enlaces. Para ello se podría construir una expresión regular  que busque y extraiga los valores de los enlaces:\n",
    "\n",
    "                                  href=(\"http://.+?\")\n",
    "                  \n",
    "La expresión regular busca cadenas que comiencen por “href=”http://”, seguido de uno o más caracteres (“.+?”), seguidos por otra comilla doble. El signo de interrogación añadido a “.+?” indica que se busca la cadena coincidente más pequeña posible.  Por último se añaden paréntesis a la expresión regular para indicar qué parte de la cadena localizada se quiere extraer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "url=input(\"Introduzca url: \")\n",
    "html=str(urllib.request.urlopen(url).read())\n",
    "enlaces=re.findall('href=\"(http://.+?)\"',html)\n",
    "for enlace in enlaces:\n",
    "    print(enlace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método findall de las expresiones regulares proporciona una lista de todas las cadenas que coinciden con la expresión regular, devolviendo sólo el texto del enlace situado dentro de las comillas dobles.\n",
    "\n",
    "Las expresiones regulares funcionan bien cuando el HTML está bien formado y es predecible. Sin embargo si el HTML no está bien construido, se pueden perder parte de los enlaces correctos, o terminar obteniendo datos erróneos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BeautifulSoup__\n",
    "\n",
    "BeautifulSoup es un módulo para extraer información de un página web.\n",
    "\n",
    "Se puede descargar e “instalar” desde http://www.crummy.com/software/ o simplemente colocar el archivo BeautifulSoup.py en la misma carpeta que nuestra aplicación.\n",
    "\n",
    "En este ejemplo se va analizar una página web y se van a extraer todos sus enlaces. Para ello el programa solicita una dirección web, luego abre la página web usando urllib, se leen los datos y se los pasa al analizador BeautifulSoup, que recupera todas las etiquetas de anclas(a) e imprime en pantalla el atributo href de cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "url=input(\"Introduzca url: \")\n",
    "html=urllib.request.urlopen(url).read()\n",
    "soup=BeautifulSoup(html, 'html.parser')\n",
    "etiquetas=soup(\"a\")\n",
    "for etiqueta in etiquetas:\n",
    "    print (etiqueta.get(\"href\",None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar que el método BeautifulSoup() también admite como entrada un archivo html que esté descargado en el disco duro local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "html=open(\"Facultad de Informática.html\")\n",
    "soup=BeautifulSoup(html, 'html.parser')\n",
    "etiquetas=soup(\"a\")\n",
    "for etiqueta in etiquetas:\n",
    "    print (etiqueta.get(\"href\",None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método BeautifulSoup() genera un objeto de tipo BeautifulSoup que tiene un conjunto de métodos que se pueden utilizar para localizar partes específicas de un documento html.\n",
    "\n",
    "En el siguiente ejemplo se van a extraer varías partes de una etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "url=input(\"Introduzca url: \")\n",
    "html=urllib.request.urlopen(url).read()\n",
    "soup=BeautifulSoup(html, 'html.parser')\n",
    "#Recupera todas las etiquetas de anclaje\n",
    "etiquetas=soup(\"a\")\n",
    "#Busca las partes de una etiqueta\n",
    "for etiqueta in etiquetas:\n",
    "    print(\"ETIQUETA: \", etiqueta)\n",
    "    print(\"URL:\",etiqueta.get(\"href\",None))\n",
    "    print(\"Contenidos:\",str(etiqueta.contents[0]))\n",
    "    print(\"Atributos:\",etiqueta.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general BeautifulSoup se puede usar para diferentes acciones:\n",
    "\n",
    "* Imprimir un documento\n",
    "\n",
    "* Parsear un documento html\n",
    "\n",
    "* Analizar un documento html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Imprimir un documento html__\n",
    "\n",
    "Existen varios métodos para imprimir un documento:\n",
    "\n",
    "* La función __str()__ muestra el documento como una cadena, pero no elimina nodos que solo tengan un espacio en blanco ni añade espacios en blanco entre los nodos.\n",
    "\n",
    "* La función __prettify()__ añade nuevas líneas y espacios para mostrar la estructura del documento html, y elimina nodos que solo contengan espacios en blanco.\n",
    "\n",
    "* La función __encode_contents__ muestra el documento como una cadena en la codificación dada, y si no se indica se muestra como una cadena unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "doc=\"<html><h1>Cabecera</h1><p>Text\"\n",
    "soup=BeautifulSoup(doc, 'html.parser')\n",
    "print(str(soup))\n",
    "print()\n",
    "print(soup.encode_contents())\n",
    "print()\n",
    "print(soup.__str__())\n",
    "print()\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones __str__ y __encode_contents__ no funcionan igual cuando se usa sobre una etiqueta dentro del documento. En el caso de __str__ se imprime la etiqueta y sus contenidos y en el caso de __encode_contents__ solo se imprimen los contenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Cabecera</h1>\n",
      "\n",
      "b'Cabecera'\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "doc=\"<html><h1>Cabecera</h1><p>Text\"\n",
    "soup=BeautifulSoup(doc, 'html.parser')\n",
    "cabecera=soup.h1\n",
    "print (str(cabecera))\n",
    "print()\n",
    "print(cabecera.encode_contents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se llama a __str__, __prettify__ o __encode_contents__ se puede especifica la codificación de salida de la cadena. Por defecto es UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sacré bleu!\n",
      "b'Sacr\\xe9 bleu!\\n'\n",
      "b'\\xff\\xfeS\\x00a\\x00c\\x00r\\x00\\xe9\\x00 \\x00b\\x00l\\x00e\\x00u\\x00!\\x00\\n\\x00'\n",
      "b'Sacr\\x8f\\xab\\xb1 bleu!\\n'\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "doc=\"Sacr\\xe9 bleu!\"\n",
    "soup=BeautifulSoup(doc, 'html.parser')\n",
    "print(str(soup))\n",
    "print(soup.prettify(encoding=\"ISO-8859-1\"))\n",
    "print(soup.prettify(encoding=\"UTF-16\"))\n",
    "print(soup.prettify(encoding=\"EUC-JP\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el documento original contenía una especificación de codificación entonces se reescribe cuando se convierte a cadena a UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "doc=\"\"\"<html>\n",
    "<meta http-equiv=\"Content-type\" content=test/html; charset=ISO-Latin-1\">\n",
    "Sacr\\xe9 bleu!\n",
    "</html>\"\"\"\n",
    "print (BeautifulSoup(doc, 'html.parser').prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parsear un documento html__\n",
    "\n",
    "BeautifulSoup toma un documento html y lo parsea a una estructura de datos en forma de árbol. Si el documento está bien formado el árbol se parece al documento original pero si no lo está entonces usa heurísticas para conseguir una estructura razonable. \n",
    "\n",
    "En este sentido se usa el siguiente conocimiento:\n",
    "\n",
    "* Hay etiquetas que pueden estar anidadas(&lt;BLOCKQUOTE/>) y otras no(&lt;P/>).\n",
    "\n",
    "* Las tablas y listas de etiquetas tienen un orden de anidamiento natural. Por ejemplo &lt;TD> está en el interior de &lt;TR>.\n",
    "\n",
    "* Los contenidos de una etiqueta &lt;SCRIPT> no deben ser parseados.\n",
    "\n",
    "* Una etiqueta &lt;META> puede especificar una codificación del documento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <p>\n",
      "  Parra 1\n",
      "  <p>\n",
      "   Parra 2\n",
      "   <blockquote>\n",
      "    Quote 1\n",
      "    <blockquote>\n",
      "     Quote 2\n",
      "    </blockquote>\n",
      "   </blockquote>\n",
      "  </p>\n",
      " </p>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html=\"<html><p>Parra 1<p> Parra 2<blockquote>Quote 1<blockquote>Quote 2\"\n",
    "soup=BeautifulSoup(html, 'html.parser')\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <form>\n",
      "  <table>\n",
      "   <td>\n",
      "    <input name=\"input1\"/>\n",
      "    Row 1 cell 1\n",
      "    <tr>\n",
      "     <td>\n",
      "      Row 2 cell 1\n",
      "     </td>\n",
      "    </tr>\n",
      "   </td>\n",
      "  </table>\n",
      " </form>\n",
      " <td>\n",
      "  Row 2 cell 2\n",
      "  <br/>\n",
      "  This  sure is a long cell\n",
      " </td>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html=\"\"\"\n",
    "<html>\n",
    "<form>\n",
    "<table>\n",
    "<td><input name=\"input1\"> Row 1 cell 1\n",
    "<tr> <td> Row 2 cell 1\n",
    "</form>\n",
    "<td> Row 2 cell 2 <br> This </br> sure is a long cell\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "print(BeautifulSoup(html, 'html.parser').prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto Beautifulsoup representa un árbol de procesamiento que contiene dos tipos de objetos:\n",
    "\n",
    "* Objetos de tipo tag que se corresponden con etiquetas o elementos del documento HTML\n",
    "\n",
    "* Objetos de tipo NavigableString que se corresponden con cadenas. Existen subclases de NavigableString que corresponden a construcciones especiales XML tales como CData, Comment, Declaration, and ProcessingInstruction.\n",
    "\n",
    "Los elementos representados por los objetos de tipo tag pueden tener asociados atributos y se puede acceder a ellos como si fuera un diccionario. Sin embargo los elementos representados por los objetos NavigableString no tienen asociados atributos.\n",
    "\n",
    "Considerar el siguiente ejemplo para las explicaciones siguientes:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<html>\n",
    " <head>\n",
    "  <title>\n",
    "  Título de la página\n",
    "  </title>\n",
    "  </head>\n",
    "  <body>\n",
    "  <p id=\"primerparrafo\" align=\"center\">\n",
    "  Esto es un parrafo\n",
    "  <b>\n",
    "  one\n",
    "  </b>\n",
    "  .\n",
    "  </p>\n",
    "  <p id=\"segundoparrafo\" align=\"blah\">\n",
    "  Esto es un parrafo\n",
    "  <b>\n",
    "  two\n",
    "  </b>\n",
    "  .\n",
    "  </p>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo se recuperan las etiquetas “p” y se accede a sus atributos como si fuera un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primerparrafo\n",
      "segundoparrafo\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html=open(\"prueba.html\")\n",
    "soup=BeautifulSoup(html.read(),'html.parser')\n",
    "Primero, Segundo=soup.find_all(\"p\")\n",
    "print (Primero['id'])\n",
    "print (Segundo['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores tag pueden ser pasados a la función str() para mostrar las etiquetas que representan. Además los valores tag tienen un atributo llamado attrs que muestra todos los atributos HTML que tiene el elemento en forma de un diccionario.\n",
    "\n",
    "Los objetos Tag y NavigableString disponen de un conjunto de atributos y métodos:\n",
    "\n",
    "* __parent__: Permite acceder al objeto que representa la etiqueta padre del objeto que representa a  una etiqueta. Permite navegar por el árbol de procesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head.parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __contents__: Representa una lista ordenada de los objetos Tags y NavigableString contenidos dentro de un elemento. Solo el objeto que representa al árbol y los objetos tags poseen este atributo. Los objetos NavigableString no tienen el atributo contents, pues sólo tienen cadenas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esto es un parrafo', <b>one</b>, '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetasp=soup.p\n",
    "etiquetasp.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetasp.contents[1].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-34ebbca114f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0metiquetasp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    644\u001b[0m             raise AttributeError(\n\u001b[0;32m    645\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[1;32m--> 646\u001b[1;33m                     self.__class__.__name__, attr))\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moutput_ready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "etiquetasp.contents[0].contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __string__: Si un tag solo tiene un nodo hijo y se trata de una cadena, entonces se puede acceder al mismo mediante tag.string o mediante tag.contents[0]. Cuando existen hijos, y se trata de acceder al atributo string, devuelve como resultado el valor None. Los objetos NavigableString no tienen este atributo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.b.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.b.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p.string==None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.string==None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __next_sibling__ y __previous_sibling__: Permite recuperar el objeto anterior o posterior que se encuentra al mismo nivel del objeto considerado. En el ejemplo anterior la etiqueta &lt;Body> está al mismo nivel que la etiqueta &lt;Head> pero esta última aparece antes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head.next_sibling.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head.previous_sibling==None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __next__ y __previous__: Permiten navegar en el árbol de procesamiento sobre los objetos en el orden en que fueron procesados en vez del orden dado por el árbol. En el ejemplo el objeto next al objeto que representa a &lt;HEAD> es el objeto que representa a &lt;TITLE> y no el objeto que representa a &lt;BODY>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.next_sibling.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.previous.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "\n",
    "* Se puede iterar sobre el atributo contents de un objeto tag y tratarlo como una lista, y de forma similar se puede obtener el número de hijos mediante len(tag) o len(tag.contents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.body:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.body.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puede usar los nombres de un objeto tag como si fueran atributos del árbol de procesamiento o de un objeto tag. Siempre que se usa de esta forma, devuelve el primer nodo hijo cuyo nombre sea el considerado o bien retorna None si no existen hijos con ese nombre. En el ejemplo anterior para acceder a la etiqueta &lt;Title> se puede ir a partir de la etiqueta &lt;Head> o bien directamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ahora se van a considerar los métodos que permiten buscar en el árbol de procesamiento: find_all y find.\n",
    "\n",
    "* Solo se encuentran disponibles para el objeto que representa el árbol de procesamiento y en los objetos de tipo tag pero no en los objetos de tipo NavigableString\n",
    "\n",
    "El método find_all busca todos los objetos tag y NavigableString  que coinciden con un criterio dado desde un punto dado. Sus principales argumentos son:\n",
    "\n",
    "               find_all(name, attrs, recursive, text, limit)\n",
    "\n",
    "donde:\n",
    "               \n",
    "* Un nombre que restringe el conjunto de búsqueda por el nombre de las etiquetas.\n",
    "\n",
    "* Pares atributo-valor que restringen el conjunto de búsqueda por los valores que toman los atributos de las etiquetas.\n",
    "\n",
    "* El argumento “text” permite buscar objetos NavigableString , y puede tomar como valores una cadena, una expresión regular, una lista o diccionario, True o None o bien una expresión booleana. Cuando se usa este argumento, las restricciones sobre nombre o atributo no se tienen en cuenta.\n",
    "\n",
    "* El argumento “recursive” que puede tomar los valores True o False que indica si busca por debajo del árbol o bien por los hijos inmediatos del árbol. Por defecto es True.\n",
    "\n",
    "* El argumento limit permite parar la búsqueda cuando se han conseguido un número de coincidencias dado. Por defecto no tienen límite.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos de restricción por nombre:\n",
    "\n",
    "* Argumento con el nombre de una etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento con una expresión regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "etiquetasconb=soup.find_all(re.compile('^b'))\n",
    "for tag in etiquetasconb:\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento con una lista o diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(['title','p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all({'title':True,'p':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento con el valor True que produce una coincidencia con cada objeto tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas=soup.find_all(True)\n",
    "for tag in etiquetas:\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento con una expresión que evalúa a cierto o falso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(lambda tag: len(tag.attrs)==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(lambda tag: len(tag.name)==1 and not tag.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos de restricción por atributo:\n",
    "\n",
    "* Argumento que impone una condición al valor que toma un atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(align=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento que impone una condición en forma de expresión regular al valor que toma un atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(id=re.compile(\"parra$\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento que impone una condición en forma de lista al valor que toma un atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(align=[\"center\",\"blah\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento que impone una condición en forma de una expresión booleano al valor que toma un atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(align=lambda value: value and len(value) <5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Argumento que iguala a True o None el valor de un atributo. True encaja con etiquetas que toman cualquier valor para el atributo y None encaja con etiquetas que no tienen valor para ese atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(align=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas=soup.find_all(align=None)\n",
    "for eti in etiquetas:\n",
    "    print(eti.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos del argumento text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(text=\"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(text=[\"one\",\"two\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(text=lambda x: len(x)<12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(text=re.compile(\"parrafo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos del argumento recursive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tag.name for tag in soup.html.find_all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tag.name for tag in soup.html.find_all(recursive=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos del argumento limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p',limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p',limit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método find tiene una estructura similar a find_all:\n",
    "          \n",
    "           find(name, attrs, recursive, text)\n",
    "\n",
    "Es similar a find_all con la única diferencia de que en vez de recuperar todas las coincidencias, recupera sólo la primera. Tiene el mismo comportamiento que si el parámetro limit de find_all tomara el valor 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p', limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "\n",
    "* Puede ocurrir que algún atributo de una etiqueta coincida con las palabras reservadas en BeautifulSoup. En estos casos no se puede hacer una referencia directa al atributo y es necesario usar un atributo que tienen las etiquetas denominado attrs que actúa como un diccionario que hace referencia a los atributos de una etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(attrs={\"id\":\"primerparrafo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se pueden combinar búsqueda por nombre y por atributo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p',{\"align\":\"center\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cuando el objeto que representa al árbol de procesamiento o un objeto tag se usa como una función y se le pasan los mismos argumentos que a find_all, actúa como find_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup(text=lambda x: len(x)<12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body('p',limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los métodos find_all y find empiezan en un cierto punto del árbol y lo recorren hacia abajo, iterando recursivamente sobre los elementos del atributo contents de los objetos tags. Es por ello que no se pueden usar sobre objetos de tipo NavigableString pues no tienen atributo contents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen otros métodos de navegación por el árbol de procesamiento:\n",
    "\n",
    "* find_next_siblings(name, attrs, text, limit) y find_next_sibling(name, attrs, text): Devuelve el nodo/s hermano/s más cercanos a la etiqueta dada que coincida con los criterios de búsqueda y que aparece después de la etiqueta considerada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrafo=soup.find(text=\"Esto es un parrafo\")\n",
    "parrafo.find_next_siblings('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrafo.find_next_sibling(text=lambda text:len(text)==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find_previous_siblings(name, attrs, text, limit) y find_previous_sibling(name, attrs, text): Devuelve el nodo/s hermano/s más cercanos a la etiqueta dada que coincida con los criterios de búsqueda y que aparece antes de la etiqueta considerada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrafo=soup.find(text=\".\")\n",
    "parrafo.find_previous_siblings('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrafo.find_previous_sibling(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find_all_next(name, attrs, text, limit) y findNext(name, attrs, text):                                                Devuelve todos los elementos(el elemento) que coincida con los criterios de búsqueda y que aparece después de la etiqueta considerada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta=soup.find('p')\n",
    "etiqueta.find_all_next(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta.find_next('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta.find_next('b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find_all_previous(name, attrs, text, limit) y find_previous(name, attrs, text):                            Devuelve todos los elementos(el elemento) que coincida con los criterios de búsqueda y que aparece antes de la etiqueta considerada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta=soup('p')[-1]\n",
    "etiqueta.find_all_previous(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta.find_previous('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta.find_previous('b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find_parents(name, attrs, limit) y find_parent(name, attrs):                                                       Devuelve los padres de la etiqueta considerada que coinciden con los criterios de búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta=soup.find('b')\n",
    "[eti.name for eti in etiqueta.find_parents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta.find_parent('body').name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra utilidad que ofrece BeautifulSoup es la modificación del árbol de procesamiento:\n",
    "\n",
    "* Cambio de valores de atributos.\n",
    "\n",
    "* Eliminación de elementos.\n",
    "\n",
    "* Reemplazamiento de un elemento por otro.\n",
    "\n",
    "* Añadir una rama con un nuevo elemento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cambio de valores de atributos__\n",
    "\n",
    "* Se puede usar la asignación de diccionarios para modificar los valores de los atributos de un objeto tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(\"<b id='2'> Argh!</b>\",\"html.parser\")\n",
    "print(soup)\n",
    "b=soup.b\n",
    "b['id']=10\n",
    "print(soup)\n",
    "b['id']=\"diez\"\n",
    "print(soup)\n",
    "b['id']=\"un millón\"\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se pueden eliminar atributos y añadir otros nuevos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(\"<b id='2'> Argh!</b>\",\"html.parser\")\n",
    "b=soup.b\n",
    "del(b['id'])\n",
    "print(soup)\n",
    "b[\"class\"]=\"extra negro\"\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Eliminación de elementos__\n",
    "\n",
    "Cuando se sitúa sobre un elemento concreto, se puede eliminar del árbol de procesamiento con el método extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan todos los comentarios del documento html\n",
    "from bs4 import BeautifulSoup,Comment\n",
    "soup=BeautifulSoup(\"\"\" 1<!--Comentario 1-->\n",
    "                        <a>2<!--Comentario 2--><b>3\"\"\", \"html.parser\")\n",
    "comentarios=soup.find_all(text=lambda text: isinstance(text,Comment))\n",
    "[comentario.extract() for comentario in comentarios]\n",
    "print (\"Eliminación de todos los comentarios del documento html\")\n",
    "print (soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación de un subárbol entero que da lugar a dos árboles disjuntos\n",
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(\"<a1></a1><a><b>Contenido de prueba<c><d></a><a2></a2>\", \"html.parser\")\n",
    "print (soup.a1.next_sibling)\n",
    "print (soup.a2.previous_sibling)\n",
    "subarbol=soup.a\n",
    "subarbol.extract()\n",
    "print (soup)\n",
    "print (soup.a1.next_sibling)\n",
    "print (soup.a2.previous_sibling)\n",
    "print (subarbol.previous_sibling==None)\n",
    "print (subarbol.parent==None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reemplazar un elemento por otro__\n",
    "\n",
    "El método replace_with extrae un elemento y lo reemplaza por otro que puede ser tanto un objeto de tipo tag o de tipo NavigableString. Si se pasa como argumento una cadena entonces lo considera un objeto de tipo NavigableString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo 1 de reemplazamiento del contenido de una etiqueta\n",
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(\"<b>Argh!</b>\", \"html.parser\")\n",
    "soup.find(text=\"Argh!\").replace_with(\"Buff!\")\n",
    "print(soup)\n",
    "nuevoText=soup.find(text=\"Buff!\")\n",
    "print (nuevoText.previous)\n",
    "s=nuevoText.previous.next\n",
    "print (str(s))\n",
    "print (nuevoText.parent)\n",
    "print (soup.b.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo 2 de reemplazamiento de un elemento por otro nuevo\n",
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(\"<b>Argh!<a>Hola</a></b><i>Adios</i>\", \"html.parser\")\n",
    "tag=BeautifulSoup.new_tag(soup,\"newTag\",[('id','1')])\n",
    "tag.insert(0,\"Noche\")\n",
    "soup.a.replace_with(tag)\n",
    "print (soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo 3 de reemplazamiento donde se elimina un elemento y se sustituye por\n",
    "#otro elemento del árbol de procesamiento\n",
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(\"<html>Esto es <b> un</b> ejemplo de <b> documento </b> html</html>\", \"html.parser\")\n",
    "uno,dos=soup.find_all('b')\n",
    "dos.replace_with(uno)\n",
    "print (soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Añadir una rama con un nuevo elemento.__\n",
    "\n",
    "* El método insert toma un índice sobre el atributo contents del objeto tag e inserta un nuevo elemento en dicha posición.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de creación de un árbol de procesamiento desde cero\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "soup=BeautifulSoup()\n",
    "tag1= BeautifulSoup.new_tag(soup, \"etiqueta1\")\n",
    "tag2= BeautifulSoup.new_tag(soup, \"etiqueta2\")\n",
    "tag3= BeautifulSoup.new_tag(soup, \"etiqueta3\")\n",
    "soup.insert(0,tag1)\n",
    "tag1.insert(0,tag2)\n",
    "tag1.insert(1,tag3)\n",
    "print (soup.prettify())\n",
    "text=NavigableString(\"Hola\")\n",
    "tag3.insert(0,text)\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un elemento sólo puede estar en un lugar del árbol de procesamiento. Si con el método insert se intenta insertar nuevamente un elemento, entonces es eliminado del lugar en el que estaba anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de intentar insertar un elemento dos veces\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "soup=BeautifulSoup()\n",
    "tag1= BeautifulSoup.new_tag(soup, \"etiqueta1\")\n",
    "tag2= BeautifulSoup.new_tag(soup, \"etiqueta2\")\n",
    "tag3= BeautifulSoup.new_tag(soup, \"etiqueta3\")\n",
    "soup.insert(0,tag1)\n",
    "tag1.insert(0,tag2)\n",
    "tag1.insert(1,tag3)\n",
    "print (soup.prettify())\n",
    "text=NavigableString(\"Hola\")\n",
    "tag3.insert(0,text)\n",
    "print(soup)\n",
    "tag2.insert(0,text)\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a considerar el siguiente problema. Se quiere automatizar la bajada de imágenes de tren procedentes de un blog especializado.\n",
    "\n",
    "En primer lugar recuperamos la página principal del blog mediante urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import *\n",
    "html=urllib.request.urlopen(\"http://trenesytiempos.blogspot.com.es/\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la estructura que tiene la página para ver dónde se encuentran las imágenes, y se observa que aparecen en etiquetas de anclaje que tienen entre sus atributos imageanchor=“1”.\n",
    "\n",
    "<a href=\"https://4.bp.blogspot.com/-jFeRNNxXIIk/WRbUurWfyHI/AAAAAAAAPFE/X8RtsF1f6p8RnC4ZMeMKJCDdP5d06pggACLcB/s1600/030-2569-70.jpg\n",
    "\n",
    "Se crea un árbol de procesamiento con BeautifulSoup y se recuperan todas las etiquetas con las características anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import *\n",
    "html=urllib.request.urlopen(\"http://trenesytiempos.blogspot.com.es/\").read()\n",
    "soup=BeautifulSoup(html,\"html.parser\")\n",
    "etiquetas=soup('a',{\"imageanchor\":\"1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperadas las direcciones se quieren almacenar las imágenes en el disco local, entonces para ello se usa un bucle for que recorre cada dirección, la abre y la almacena en un archivo distinto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in etiquetas:\n",
    "    archivo=open(\"foto\"+str(j)+\".jpg\",\"wb\")\n",
    "    imagen=urllib.request.urlopen(i.get(\"href\",None))\n",
    "    while True:\n",
    "        info=imagen.read(100000)\n",
    "        if len(info)<1: \n",
    "            break\n",
    "        archivo.write(info)\n",
    "    archivo.close()\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código completo sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import *\n",
    "html=urllib.request.urlopen(\"http://trenesytiempos.blogspot.com.es/\").read()\n",
    "soup=BeautifulSoup(html,\"html.parser\")\n",
    "etiquetas=soup('a',{\"imageanchor\":\"1\"})\n",
    "j=0\n",
    "for i in etiquetas:\n",
    "    archivo=open(\"foto\"+str(j)+\".jpg\",\"wb\")\n",
    "    imagen=urllib.request.urlopen(i.get(\"href\",None))\n",
    "    while True:\n",
    "        info=imagen.read(100000)\n",
    "        if len(info)<1: \n",
    "            break\n",
    "        archivo.write(info)\n",
    "    archivo.close()\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Otras herramientas__\n",
    "\n",
    "La función open del módulo webbrowser de Python permite lanzar un navegador sobre una URL específica. Por ejemplo el siguiente trozo de código abriría un navegador con la página de la Facultad de Informática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open(\"http://informatica.ucm.es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a considerar un programa que recupera del teclado una dirección y que permite buscar dicha dirección en Google Maps.Para ello en primer lugar observar que la url que se usa cuando se busca una dirección en Google Maps tiene la siguiente estructura:\n",
    "    https://www.google.com/maps/place/dirección-buscada\n",
    "    \n",
    "El programa debe recuperar de la línea de comandos la dirección . Para ello se usará el módulo sys que permite almacena en la variable sys.argv una lista con el nombre del programa y los argumentos pasados al programa en caso de tenerlos. Para saber si la lista incluye más elementos además del nombre del programa, se puede utilizar len(sys.argv) y comprobar que se evalúa a un número mayor que 1.\n",
    "\n",
    "Se tiene el siguiente código:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "if len(sys.argv)>1:\n",
    "    direccion=' '.join(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar que los argumentos en la línea de comandos en general se separan mediante espacios, sin embargo en este caso sería necesario interpretar todos los argumentos como una única cadena. Dado que sys.argv es una lista de cadenas, se puede utilizar el método join() que retorna una única cadena. Además como no interesa el nombre del programa, se puede eliminar el mismo si se selecciona la última parte de la lista con sys.argv[1:]\n",
    "\n",
    "Si en la línea de comandos no hay argumentos, se asumirá que la dirección se ha copiado. Para obtener el contenido de una copia se utiliza el método paste del módulo pyperclip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys, pyperclip\n",
    "if len(sys.argv)>1:\n",
    "    direccion=' '.join(sys.argv[1:])\n",
    "else:\n",
    "    direccion=pyperclip.paste()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último para lanzar el navegador se utiliza el método open del módulo browser.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys, pyperclip, webbrowser\n",
    "if len(sys.argv)>1:\n",
    "    direccion=' '.join(sys.argv[1:])\n",
    "else:\n",
    "    direccion=pyperclip.paste()\n",
    "webbrowser.open(\"http://www.google.com/maps/place/\"+direccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
